{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended Sites for Pandas\n",
    "\n",
    "* [Datascience Made Simple](http://www.datasciencemadesimple.com)\n",
    "* [Pandas tutorial by dataquest](https://www.dataquest.io/blog/pandas-python-tutorial/) [Blog]\n",
    "* [Pandas official doc](http://pandas.pydata.org/pandas-docs/stable/) [Highly recommended]\n",
    "* [Experiments with data](https://trainings.analyticsvidhya.com/courses/course-v1:AnalyticsVidhya+EWD01+2018_EWD_T1/about) [Course]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance Pandas\n",
    "\n",
    "In this notebook, we will be going through a lot of different concepts (that will help you all realize why pandas is so much important when it comes to Data Analysis). Mastering all the following concepts is not at all important, but knowing that they exist can be an advantage. You can always learn these concepts as and when your task in hand demands. These are all the concepts that are mentioned in this notebook\n",
    "* [Sorting with nlargest, nsmallest and sort_values](#Sorting with nlargest, nsmallest and sort_values)\n",
    "* [Replacing values in dataframe/series](#Replacing values in dataframe/series)\n",
    "* [Renaming columns and indexes in datafram/series](#Renaming columns and indexes in datafram/series)\n",
    "* [Handling Missing Values](#Handling Missing Values)\n",
    "* [Descriptive stats](#Descriptive stats)\n",
    "* [Combining dataframes](#Combining dataframes)\n",
    "* [String manipulations in pandas](#String manipulations in pandas)\n",
    "* [Plotting in pandas](#Plotting in pandas)\n",
    "\n",
    "<span style=\"color:brown\">** Note: **</span> All the concepts are not covered completely. Links to documentation are provided for most of the concepts covered here, do visit them if you want to learn them in greater details or to master them. (recommended !)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/sample_data.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting with nlargest, nsmallest and sort_values\n",
    "\n",
    "### <span style=\"color:brown\"><b>Note :</b></span> In all the 3 methods, an ERROR is raised if dtype of the column is not supported.\n",
    "\n",
    "###  nlargest\n",
    "\n",
    "~~~ python\n",
    "    > df.nlargest(n,columns)\n",
    "~~~\n",
    "\n",
    "where,<br>\n",
    "*n - selects the number of row to be returned<br>\n",
    "*columns - the columns that are to be considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.nlargest(3,['height'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  nsmallest\n",
    "\n",
    "~~~ python\n",
    "    > df.nsmallest(n,columns)\n",
    "~~~\n",
    "\n",
    "where,<br>\n",
    "*n - selects the number of row to be returned<br>\n",
    "*columns - the columns that are to be considered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.nsmallest(3,['height','age','score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort_values\n",
    "\n",
    "~~~ python\n",
    "    > df.sort_values(by,ascending)\n",
    "~~~\n",
    "\n",
    "where,<br>\n",
    "*by - the column name(s) that are to be considered<br>\n",
    "*ascending - True/False, default is *True*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('age', ascending=True).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing values in dataframe/series\n",
    "\n",
    "General syntax for replace function is as follows:\n",
    "\n",
    "~~~ python\n",
    "    > df.replace(to_replace, value)\n",
    "~~~\n",
    "\n",
    "**to_replace** and **value** both can be *str, regex, list, dict, Series, int, float, or None* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
    "                    'B': [5, 6, 7, 8, 9],\n",
    "                    'C': ['a', 'b', 'c', 'd', 'e']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List-like `to_replace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([0, 1, 2, 3], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.replace([0, 1, 2, 3], [4, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dict-like `to_replace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({0: 10, 1: 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'A': 0, 'B': 5}, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace({'A': {0: 100, 4: 400}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns and indexes in datafram/series\n",
    "\n",
    "General syntax for rename function is as follows:\n",
    "\n",
    "    > df.rename(index, columns)\n",
    "\n",
    "index and columns both are *dict-like*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"A\": \"a\", \"B\": \"c\"}, index={0:100})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(index={0: \"zero\", \"B\": \"c\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fillna()\n",
    "\n",
    "    > df.fillna(value)\n",
    "   \n",
    "*value - scalar, dict*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[np.nan, 2, np.nan, 0],\n",
    "                    [3, 4, np.nan, 1],\n",
    "                    [np.nan, np.nan, np.nan, 5],\n",
    "                    [np.nan, 3, np.nan, 4]],\n",
    "                    columns=list('ABCD'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
    "df.fillna(value=values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropna\n",
    "\n",
    "    > df.dropna(axis=0, how='any', thresh=None, subset=None)\n",
    "    \n",
    "* **how** - {'all', 'any'}, default is 'any'.<br>\n",
    "* **thresh** - How many non-NA values Require.<br>\n",
    "* **subset** - Labels along other axis to consider.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"name\": ['Alfred', 'Batman', 'Catwoman'],\n",
    "                    \"toy\": [np.nan, 'Batmobile', 'Bullwhip'],\n",
    "                    \"born\": [pd.NaT, pd.Timestamp(\"1940-04-25\"),\n",
    "                             pd.NaT]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna() # drops all the rows that have atleast one element missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1) # drops all the columns that have atleast one element missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='all')  #Drop the rows where all elements are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(thresh=2) #Keep only the rows with at least 2 non-NA values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['name', 'toy']) # Define in which columns to look for missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace \n",
    "\n",
    "#### You can also use replace() to handle missing values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive stats \n",
    "\n",
    "    > abs() - Return a Series/DataFrame with absolute numeric value of each element.\n",
    "    > count() - Count non-NA cells for each column or row.\n",
    "    > max() - returns the maximum of the values in the object.\n",
    "    > min() - returns the minimum of the values in the object.\n",
    "    > mean() - returns the mean of the values in the object.\n",
    "    > median() - returns the median of the values in the object.\n",
    "    > mode() - returns the mode of the values in the object.\n",
    "    > sum() - returns the sum of the values in the object.\n",
    "\n",
    "<span style=\"color:brown\"> **Note: **</span> all the methods take *axis* as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/sample_data.csv', index_col=0)\n",
    "df = df[['age', 'height', 'score']].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['score'] = 5\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['height'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### value_counts()\n",
    "\n",
    "    Returns object containing counts of unique values.\n",
    "<span style=\"color:brown\"> **Note: **</span> only specific to series data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining dataframes\n",
    "\n",
    "Pandas provides various facilities for easily combining together Series and DataFrame.<br>\n",
    "<span style=\"color:brown\">** Note:** </span> refer the [Merge, join and concat documentation](https://pandas.pydata.org/pandas-docs/stable/merging.html) for details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat() - based on index / column labels\n",
    "\n",
    "    > pd.concat(objs, axis=0, join='outer', join_axes=None)\n",
    "    \n",
    "   * **axis** : {0, 1, …}, default 0. The axis to concatenate along.\n",
    "   * **join** : {‘inner’, ‘outer’}, default ‘outer’. How to handle indexes on other axis(es). Outer for union and inner for intersection.\n",
    "   * **join_axes** : list of Index objects. Specific indexes to use for the other n - 1 axes instead of performing inner/outer set logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                     'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                     'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                     'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                     index=[0, 1, 2, 3]) \n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                     'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                     'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                     'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                      index=[4, 5, 6, 7])\n",
    " \n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                     'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                     'C': ['C8', 'C9', 'C10', 'C11'],\n",
    "                     'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                     index=[8, 9, 10, 11])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([df1,df2,df3], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/merging_concat_basic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                     'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                     'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                    index=[2, 3, 6, 7])\n",
    "\n",
    "result2 = pd.concat([df1, df4], axis=1)\n",
    "result2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/merging_concat_axis1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append() \n",
    "\n",
    "A useful shortcut to concat() are the append() instance methods on Series and DataFrame.<br>\n",
    "Append rows of other to the end of this frame, returning a new object. Columns not in this frame are added as new columns\n",
    "~~~ python\n",
    "> df.append(df2)\n",
    "~~~   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge and join - based on key values\n",
    "#### Merge()\n",
    " Pandas provide join operations very similar to relational databases like SQL. *merge()*,a single function,  as the entry point for all standard database join operations between DataFrame objects\n",
    " ~~~ python\n",
    "> pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None)\n",
    " ~~~\n",
    " * **how:** {'left', 'right', 'outer', 'inner'}. Defaults to inner.<br>\n",
    " \n",
    "#### Join()\n",
    "Join columns with other DataFrame either on index or on a key column. Efficiently Join multiple DataFrame objects by index at once by passing a list.\n",
    "~~~ python\n",
    "> DataFrame.join(other, on=None, how='left') \n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String manipulations in pandas\n",
    "\n",
    "Python has long been a popular raw data manipulation language in part due to its ease of use for string and text processing. Most text operations are made simple with the string object’s built-in methods. For more complex pattern matching and text manipulations, regular expressions may be needed. pandas adds to the mix by enabling you to apply string and regular expressions concisely on whole arrays of data, additionally handling the annoyance of missing data\n",
    "\n",
    "Pandas is extremely power extremely powerful when its comes to text data. Go through [the documentation](https://pandas.pydata.org/pandas-docs/stable/text.html) and you will realize its!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting in pandas\n",
    "\n",
    "Rememebered, pandas is python library for data manipulation and data analysis. Untill now we have mostly looked at the manipulation part. You can plot your Pandas dataframes and series for visualization and analysis. Pandas have many powerful built-in functoins for data visualization and also, are very easy to use.\n",
    "\n",
    "Refer [this documentation](https://pandas.pydata.org/pandas-docs/stable/visualization.html) to learn more about data visualization in pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
